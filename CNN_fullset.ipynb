{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ab76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d3a1404-697f-479f-9090-c1ecd0413d27</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0c03127-9dfb-4573-8934-1958396937bf</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>3855ea22-5e7f-411f-b1fa-6db27a676c06</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>dfd4079d-967b-4b3e-8574-fbac11b58103</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>5379356a-40ee-4890-b416-2336a7d84061</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>65507fb8-3456-4c15-b53e-d1b03bf71a59</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>32b99302-cec7-4dec-adfa-3d4029674209</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4677 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image    label\n",
       "0     ea7b6656-3f84-4eb3-9099-23e623fc1018      Top\n",
       "1     ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa      Top\n",
       "2     3b86d877-2b9e-4c8b-a6a2-1d87513309d0    Shoes\n",
       "3     5d3a1404-697f-479f-9090-c1ecd0413d27  Bottoms\n",
       "4     b0c03127-9dfb-4573-8934-1958396937bf      Top\n",
       "...                                    ...      ...\n",
       "4672  3855ea22-5e7f-411f-b1fa-6db27a676c06    Shoes\n",
       "4673  dfd4079d-967b-4b3e-8574-fbac11b58103  Bottoms\n",
       "4674  5379356a-40ee-4890-b416-2336a7d84061  Bottoms\n",
       "4675  65507fb8-3456-4c15-b53e-d1b03bf71a59    Shoes\n",
       "4676  32b99302-cec7-4dec-adfa-3d4029674209  Bottoms\n",
       "\n",
       "[4677 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('images_2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a415f90",
   "metadata": {},
   "source": [
    "# Encode labels, take sample of data into train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fa1093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df.label)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27a5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78eb944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, test_index in ss.split(images, labels):\n",
    "    train_x, test_x = images[train_index], images[test_index]\n",
    "    train_y, test_y = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupational-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62edb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, valid_index in ss.split(train_x, train_y):\n",
    "    train_x, valid_x = train_x[train_index], train_x[valid_index]\n",
    "    train_y, valid_y = train_y[train_index], train_y[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f2438",
   "metadata": {},
   "source": [
    "# Get all images loaded in from sample and convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ddbd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def get_images(path_list):\n",
    "    train_img = []\n",
    "    for filename in path_list:\n",
    "        path = 'images_compressed/' + filename + '.jpg'\n",
    "        img = imread(path, as_gray=True)\n",
    "        img = resize(img, (100, 100))\n",
    "        img /= 255.0\n",
    "        img = img.astype('float32')\n",
    "        train_img.append(img)\n",
    "    return np.asarray(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f3c1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_images = get_images(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50b3113b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2992, 100, 100)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7170de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_images = get_images(valid_x)\n",
    "test_x_images = get_images(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03257ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_x_torch = torch.from_numpy(train_x_images).unsqueeze(dim=1)\n",
    "valid_x_torch = torch.from_numpy(valid_x_images).unsqueeze(dim=1)\n",
    "test_x_torch = torch.from_numpy(test_x_images).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "788aa0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2992, 1, 100, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0f31717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2992])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_torch = torch.from_numpy(train_y)\n",
    "valid_y_torch = torch.from_numpy(valid_y)\n",
    "test_y_torch = torch.from_numpy(test_y)\n",
    "train_y_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2bda2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if available\n",
    "if torch.cuda.is_available():\n",
    "    train_x_torch = train_x_torch.cuda()\n",
    "    train_y_torch = train_y_torch.cuda()\n",
    "    valid_x_torch = valid_x_torch.cuda()\n",
    "    valid_y_torch = valid_y_torch.cuda()\n",
    "    test_x_torch = test_x_torch.cuda()\n",
    "    test_y_torch = test_y_torch.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08cc17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(zip(train_x_torch, train_y_torch.to(dtype=torch.long)))\n",
    "test = list(zip(test_x_torch, test_y_torch.to(dtype=torch.long)))\n",
    "valid = list(zip(valid_x_torch, valid_y_torch.to(dtype=torch.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything into a data loader because too much data for gpu\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=16)\n",
    "testloader = DataLoader(test, batch_size=16)\n",
    "validloader = DataLoader(valid, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b1cb5",
   "metadata": {},
   "source": [
    "# Create CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cab59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# need to figure out what the numbers in Conv2d and other parts are / what to use for them\n",
    "\n",
    "class ConvNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        \n",
    "        # two layers for this cnn\n",
    "        self.cnn_layers = nn.Sequential (\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(1, 32, kernel_size=9, stride=1, padding=1),   # output = 94 x 94 x 32\n",
    "            nn.BatchNorm2d(32),                                     # same shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # output = 47 X 47 X 32\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(32, 32, kernel_size=9, stride=1, padding=1),  # output = 41 X 41 X 32\n",
    "            nn.BatchNorm2d(32),                                     # same shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # output = 20 X 20 X 32\n",
    "      \n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(32 * 20 * 20, 10)\n",
    "        )\n",
    "        \n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4bfc6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNN(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=12800, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "model = ConvNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00952669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0 loss = 0.763 train acc= 0.736 valid loss = 0.553 valid acc = 0.79\n",
      "At epoch 1 loss = 0.487 train acc= 0.835 valid loss = 0.429 valid acc = 0.849\n",
      "At epoch 2 loss = 0.348 train acc= 0.88 valid loss = 0.367 valid acc = 0.874\n",
      "At epoch 3 loss = 0.255 train acc= 0.913 valid loss = 0.325 valid acc = 0.88\n",
      "At epoch 4 loss = 0.19 train acc= 0.936 valid loss = 0.303 valid acc = 0.908\n",
      "At epoch 5 loss = 0.145 train acc= 0.949 valid loss = 0.301 valid acc = 0.9\n",
      "At epoch 6 loss = 0.111 train acc= 0.962 valid loss = 0.317 valid acc = 0.887\n",
      "At epoch 7 loss = 0.0858 train acc= 0.971 valid loss = 0.324 valid acc = 0.891\n",
      "At epoch 8 loss = 0.0674 train acc= 0.977 valid loss = 0.317 valid acc = 0.889\n",
      "At epoch 9 loss = 0.0536 train acc= 0.984 valid loss = 0.311 valid acc = 0.899\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        for i in range(len(labels)):\n",
    "            image = images[i].view(1, 1, 100, 100)\n",
    "            with torch.no_grad():\n",
    "                logps = model(image)\n",
    "            allprobs = torch.exp(logps)\n",
    "            prob = allprobs.tolist()[0]\n",
    "            hyp = prob.index(max(prob))\n",
    "            train_y = labels[i]\n",
    "            train_total += 1\n",
    "            if train_y.item() == hyp:\n",
    "                train_correct += 1\n",
    "                \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    \n",
    "    model.eval()\n",
    "    for images, labels in validloader:\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        valid_loss += loss.item()\n",
    "        for i in range(len(labels)):\n",
    "            image = images[i].view(1, 1, 100, 100)\n",
    "            with torch.no_grad():\n",
    "                logps = model(image)\n",
    "            allprobs = torch.exp(logps)\n",
    "            prob = allprobs.tolist()[0]\n",
    "            hyp = prob.index(max(prob))\n",
    "            valid_y = labels[i]\n",
    "            valid_total += 1\n",
    "            if valid_y.item() == hyp:\n",
    "                valid_correct += 1\n",
    "                \n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "    \n",
    "    print('At epoch', epoch, 'loss =', '%.3g'%(train_loss/len(trainloader)), 'train acc=', '%.3g'%(train_correct/train_total), 'valid loss =', '%.3g'%(valid_loss/len(validloader)), 'valid acc =', '%.3g'%(valid_correct/valid_total))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "specified-string",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17577efd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92a54bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8856837606837606\n"
     ]
    }
   ],
   "source": [
    "correct = 0.\n",
    "total = 0.\n",
    "\n",
    "hyps = []\n",
    "correct_labels = []\n",
    "\n",
    "model.eval()\n",
    "for images, labels in testloader:\n",
    "    for i in range(len(labels)):\n",
    "        image = images[i].view(1, 1, 100, 100)\n",
    "        with torch.no_grad():\n",
    "            logps = model(image)\n",
    "        allprobs = torch.exp(logps)\n",
    "        prob = allprobs.tolist()[0]\n",
    "        hyp = prob.index(max(prob))\n",
    "        hyps.append(hyp)\n",
    "        test_y = labels[i]\n",
    "        total += 1\n",
    "        correct_labels.append(test_y.item())\n",
    "        if test_y.item() == hyp:\n",
    "            correct += 1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9a00344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[209,   2,   6,  14],\n",
       "       [  3,  19,   4,   8],\n",
       "       [  7,   2,  72,   6],\n",
       "       [ 40,  10,   5, 529]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(correct_labels, hyps)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "thorough-desktop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bottoms       0.81      0.90      0.85       231\n",
      "        Hats       0.58      0.56      0.57        34\n",
      "       Shoes       0.83      0.83      0.83        87\n",
      "         Top       0.95      0.91      0.93       584\n",
      "\n",
      "    accuracy                           0.89       936\n",
      "   macro avg       0.79      0.80      0.79       936\n",
      "weighted avg       0.89      0.89      0.89       936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(correct_labels, hyps, target_names=['Bottoms', 'Hats', 'Shoes', 'Top']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-latitude",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
