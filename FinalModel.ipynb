{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e36d776c",
   "metadata": {},
   "source": [
    "# Same as Test_CNN_SY but with full classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc163d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>T-Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>T-Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d3a1404-697f-479f-9090-c1ecd0413d27</td>\n",
       "      <td>Shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0c03127-9dfb-4573-8934-1958396937bf</td>\n",
       "      <td>Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>female-casual-peach-color-jeans-female-casual-...</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>lilac-jeans-wooden-background-lilac-jeans-wood...</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>jeans-image-table-48097904</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>jeans-white-background-classical-isolated-clos...</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>jeans-image-table-48100476</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5270 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image    label\n",
       "0                  ea7b6656-3f84-4eb3-9099-23e623fc1018  T-Shirt\n",
       "1                  ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa  T-Shirt\n",
       "2                  3b86d877-2b9e-4c8b-a6a2-1d87513309d0    Shoes\n",
       "3                  5d3a1404-697f-479f-9090-c1ecd0413d27   Shorts\n",
       "4                  b0c03127-9dfb-4573-8934-1958396937bf    Shirt\n",
       "...                                                 ...      ...\n",
       "5265  female-casual-peach-color-jeans-female-casual-...    Pants\n",
       "5266  lilac-jeans-wooden-background-lilac-jeans-wood...    Pants\n",
       "5267                         jeans-image-table-48097904    Pants\n",
       "5268  jeans-white-background-classical-isolated-clos...    Pants\n",
       "5269                         jeans-image-table-48100476    Pants\n",
       "\n",
       "[5270 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('images_4.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fa1093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 13, 10, ...,  7,  7,  7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df.label)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27a5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916e1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.1)\n",
    "for _, group_index in ss.split(images, labels):\n",
    "    group_x = images[group_index].to_numpy()\n",
    "    group_y = labels[group_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78eb944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, test_index in ss.split(images, labels):\n",
    "    train_x, test_x = images[train_index].to_numpy(), images[test_index].to_numpy()\n",
    "    train_y, test_y = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62edb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, valid_index in ss.split(train_x, train_y):\n",
    "    train_x, valid_x = train_x[train_index], train_x[valid_index]\n",
    "    train_y, valid_y = train_y[train_index], train_y[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f2438",
   "metadata": {},
   "source": [
    "# Get all images loaded in from sample and convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ddbd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def get_images(path_list):\n",
    "    train_img = []\n",
    "    for filename in path_list:\n",
    "        path = 'images_compressed/' + filename + '.jpg'\n",
    "        img = imread(path, as_gray=True)\n",
    "        img = resize(img, (100, 100))\n",
    "        img /= 255.0\n",
    "        img = img.astype('float32')\n",
    "        train_img.append(img)\n",
    "    return np.asarray(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f3c1d82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_x_images = get_images(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50b3113b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3372, 100, 100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7170de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_images = get_images(valid_x)\n",
    "test_x_images = get_images(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03257ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_x_torch = torch.from_numpy(train_x_images).unsqueeze(dim=1)\n",
    "valid_x_torch = torch.from_numpy(valid_x_images).unsqueeze(dim=1)\n",
    "test_x_torch = torch.from_numpy(test_x_images).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "788aa0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3372, 1, 100, 100])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0f31717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3372])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_torch = torch.from_numpy(train_y)\n",
    "valid_y_torch = torch.from_numpy(valid_y)\n",
    "test_y_torch = torch.from_numpy(test_y)\n",
    "train_y_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bda2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if available\n",
    "if torch.cuda.is_available():\n",
    "    train_x_torch = train_x_torch.cuda()\n",
    "    train_y_torch = train_y_torch.cuda()\n",
    "    valid_x_torch = valid_x_torch.cuda()\n",
    "    valid_y_torch = valid_y_torch.cuda()\n",
    "    test_x_torch = test_x_torch.cuda()\n",
    "    test_y_torch = test_y_torch.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08cc17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(zip(train_x_torch, train_y_torch.to(dtype=torch.long)))\n",
    "test = list(zip(test_x_torch, test_y_torch.to(dtype=torch.long)))\n",
    "valid = list(zip(valid_x_torch, valid_y_torch.to(dtype=torch.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "636cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything into a data loader because too much data for gpu\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=16)\n",
    "testloader = DataLoader(test, batch_size=16)\n",
    "validloader = DataLoader(valid, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b1cb5",
   "metadata": {},
   "source": [
    "# Create CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8cab59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# need to figure out what the numbers in Conv2d and other parts are / what to use for them\n",
    "\n",
    "class ConvNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        \n",
    "        self.cnn_layers = nn.Sequential (\n",
    "            # Conv 1\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=1, padding=2),   # output = 100 x 100 x 512\n",
    "            nn.BatchNorm2d(64),                                     \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                   # 50 x 50 x 512\n",
    "            # Conv 2\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),  \n",
    "            nn.BatchNorm2d(128),                                     \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                   # 25 X 25 X 512\n",
    "            # Conv 3\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.BatchNorm2d(256),                                     \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                   # 12 X 12 X 512\n",
    "            # Conv 4\n",
    "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),  \n",
    "            nn.BatchNorm2d(512),                                     \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                   # 6 X 6 X 512\n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(512 * 6 * 6, 15)\n",
    "        )\n",
    "        \n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4bfc6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNN(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (12): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=18432, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "model = ConvNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "00952669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0 loss = 1.93 train acc= 0.464 valid loss = 1.52 valid acc = 0.543\n",
      "At epoch 1 loss = 1.25 train acc= 0.604 valid loss = 1.37 valid acc = 0.588\n",
      "At epoch 2 loss = 0.895 train acc= 0.687 valid loss = 1.28 valid acc = 0.605\n",
      "At epoch 3 loss = 0.619 train acc= 0.754 valid loss = 1.26 valid acc = 0.626\n",
      "At epoch 4 loss = 0.427 train acc= 0.804 valid loss = 1.28 valid acc = 0.617\n",
      "At epoch 5 loss = 0.296 train acc= 0.835 valid loss = 1.28 valid acc = 0.63\n",
      "At epoch 6 loss = 0.214 train acc= 0.866 valid loss = 1.28 valid acc = 0.648\n",
      "At epoch 7 loss = 0.18 train acc= 0.868 valid loss = 1.2 valid acc = 0.659\n",
      "At epoch 8 loss = 0.167 train acc= 0.87 valid loss = 1.27 valid acc = 0.645\n",
      "At epoch 9 loss = 0.139 train acc= 0.883 valid loss = 1.62 valid acc = 0.6\n",
      "At epoch 10 loss = 0.117 train acc= 0.892 valid loss = 1.57 valid acc = 0.645\n",
      "At epoch 11 loss = 0.0971 train acc= 0.899 valid loss = 1.35 valid acc = 0.654\n",
      "At epoch 12 loss = 0.051 train acc= 0.919 valid loss = 1.27 valid acc = 0.685\n",
      "At epoch 13 loss = 0.0349 train acc= 0.933 valid loss = 1.27 valid acc = 0.68\n",
      "At epoch 14 loss = 0.0136 train acc= 0.944 valid loss = 1.26 valid acc = 0.691\n",
      "At epoch 15 loss = 0.00741 train acc= 0.949 valid loss = 1.21 valid acc = 0.704\n",
      "At epoch 16 loss = 0.00487 train acc= 0.952 valid loss = 1.21 valid acc = 0.707\n",
      "At epoch 17 loss = 0.00371 train acc= 0.953 valid loss = 1.2 valid acc = 0.704\n",
      "At epoch 18 loss = 0.00307 train acc= 0.954 valid loss = 1.21 valid acc = 0.707\n",
      "At epoch 19 loss = 0.00262 train acc= 0.955 valid loss = 1.21 valid acc = 0.709\n",
      "At epoch 20 loss = 0.00227 train acc= 0.955 valid loss = 1.21 valid acc = 0.71\n",
      "At epoch 21 loss = 0.00199 train acc= 0.955 valid loss = 1.21 valid acc = 0.711\n",
      "At epoch 22 loss = 0.00176 train acc= 0.955 valid loss = 1.21 valid acc = 0.713\n",
      "At epoch 23 loss = 0.00157 train acc= 0.956 valid loss = 1.22 valid acc = 0.713\n",
      "At epoch 24 loss = 0.0014 train acc= 0.956 valid loss = 1.22 valid acc = 0.714\n",
      "At epoch 25 loss = 0.00125 train acc= 0.956 valid loss = 1.22 valid acc = 0.714\n",
      "At epoch 26 loss = 0.00112 train acc= 0.956 valid loss = 1.23 valid acc = 0.716\n",
      "At epoch 27 loss = 0.001 train acc= 0.956 valid loss = 1.23 valid acc = 0.716\n",
      "At epoch 28 loss = 0.000902 train acc= 0.957 valid loss = 1.23 valid acc = 0.716\n",
      "At epoch 29 loss = 0.000811 train acc= 0.957 valid loss = 1.23 valid acc = 0.716\n",
      "Terminating early!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "ALLOWED_DROPS = 3\n",
    "drops = ALLOWED_DROPS # how many times would the validation accuracy fall before pulling the plug\n",
    "train_acc = []\n",
    "valid_acc = []\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        for i in range(len(labels)):\n",
    "            image = images[i].view(1, 1, 100, 100)\n",
    "            with torch.no_grad():\n",
    "                logps = model(image)\n",
    "            allprobs = torch.exp(logps)\n",
    "            prob = allprobs.tolist()[0]\n",
    "            hyp = prob.index(max(prob))\n",
    "            train_y = labels[i]\n",
    "            train_total += 1\n",
    "            if train_y.item() == hyp:\n",
    "                train_correct += 1\n",
    "                \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    \n",
    "    model.eval()\n",
    "    for images, labels in validloader:\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        valid_loss += loss.item()\n",
    "        for i in range(len(labels)):\n",
    "            image = images[i].view(1, 1, 100, 100)\n",
    "            with torch.no_grad():\n",
    "                logps = model(image)\n",
    "            allprobs = torch.exp(logps)\n",
    "            prob = allprobs.tolist()[0]\n",
    "            hyp = prob.index(max(prob))\n",
    "            valid_y = labels[i]\n",
    "            valid_total += 1\n",
    "            if valid_y.item() == hyp:\n",
    "                valid_correct += 1\n",
    "                \n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "    train_acc.append(train_correct/train_total)\n",
    "    valid_acc.append(valid_correct/valid_total)\n",
    "    \n",
    "    print('At epoch', epoch, 'loss =', '%.3g'%(train_loss/len(trainloader)), 'train acc=', '%.3g'%(train_correct/train_total), 'valid loss =', '%.3g'%(valid_loss/len(validloader)), 'valid acc =', '%.3g'%(valid_correct/valid_total))\n",
    "    \n",
    "    valid_acc.append(valid_correct/valid_total)\n",
    "    if valid_acc[-1] <= valid_acc[-2]:\n",
    "        drops -= 1\n",
    "        if drops == 0:\n",
    "            print('Terminating early!')\n",
    "            break\n",
    "    else:\n",
    "        drops = ALLOWED_DROPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "92a54bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.713472485768501\n"
     ]
    }
   ],
   "source": [
    "correct = 0.\n",
    "total = 0.\n",
    "\n",
    "hyps = []\n",
    "correct_labels = []\n",
    "\n",
    "for images, labels in testloader:\n",
    "    for i in range(len(labels)):\n",
    "        image = images[i].view(1, 1, 100, 100)\n",
    "        with torch.no_grad():\n",
    "            logps = model(image)\n",
    "        allprobs = torch.exp(logps)\n",
    "        prob = allprobs.tolist()[0]\n",
    "        hyp = prob.index(max(prob))\n",
    "        hyps.append(hyp)\n",
    "        test_y = labels[i]\n",
    "        total += 1\n",
    "        correct_labels.append(test_y.item())\n",
    "        if test_y.item() == hyp:\n",
    "            correct += 1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(correct_labels, hyps, target_names=['Blazer', 'Blouse', 'Dress', 'Hat', 'Hoodie', 'Longsleeve',\n",
    "       'Outwear', 'Pants', 'Polo', 'Shirt', 'Shoes', 'Shorts', 'Skirt',\n",
    "       'T-Shirt', 'Undershirt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training Accuracy')\n",
    "plt.plot(valid_losses, label='Validation Accuracy')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(frameon=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
