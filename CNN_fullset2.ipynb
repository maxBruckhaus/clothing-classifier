{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ab76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d3a1404-697f-479f-9090-c1ecd0413d27</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0c03127-9dfb-4573-8934-1958396937bf</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>3855ea22-5e7f-411f-b1fa-6db27a676c06</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>dfd4079d-967b-4b3e-8574-fbac11b58103</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>5379356a-40ee-4890-b416-2336a7d84061</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>65507fb8-3456-4c15-b53e-d1b03bf71a59</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>32b99302-cec7-4dec-adfa-3d4029674209</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4677 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image    label\n",
       "0     ea7b6656-3f84-4eb3-9099-23e623fc1018      Top\n",
       "1     ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa      Top\n",
       "2     3b86d877-2b9e-4c8b-a6a2-1d87513309d0    Shoes\n",
       "3     5d3a1404-697f-479f-9090-c1ecd0413d27  Bottoms\n",
       "4     b0c03127-9dfb-4573-8934-1958396937bf      Top\n",
       "...                                    ...      ...\n",
       "4672  3855ea22-5e7f-411f-b1fa-6db27a676c06    Shoes\n",
       "4673  dfd4079d-967b-4b3e-8574-fbac11b58103  Bottoms\n",
       "4674  5379356a-40ee-4890-b416-2336a7d84061  Bottoms\n",
       "4675  65507fb8-3456-4c15-b53e-d1b03bf71a59    Shoes\n",
       "4676  32b99302-cec7-4dec-adfa-3d4029674209  Bottoms\n",
       "\n",
       "[4677 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('images_2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a415f90",
   "metadata": {},
   "source": [
    "# Encode labels, take sample of data into train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fa1093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df.label)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27a5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78eb944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, test_index in ss.split(images, labels):\n",
    "    train_x, test_x = images[train_index], images[test_index]\n",
    "    train_y, test_y = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupational-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62edb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, valid_index in ss.split(train_x, train_y):\n",
    "    train_x, valid_x = train_x[train_index], train_x[valid_index]\n",
    "    train_y, valid_y = train_y[train_index], train_y[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f2438",
   "metadata": {},
   "source": [
    "# Get all images loaded in from sample and convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ddbd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def get_images(path_list):\n",
    "    train_img = []\n",
    "    for filename in path_list:\n",
    "        path = 'images_compressed/' + filename + '.jpg'\n",
    "        img = imread(path, as_gray=True)\n",
    "        img = resize(img, (100, 100))\n",
    "        img /= 255.0\n",
    "        img = img.astype('float32')\n",
    "        train_img.append(img)\n",
    "    return np.asarray(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3c1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_images = get_images(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b3113b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2992, 100, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7170de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_images = get_images(valid_x)\n",
    "test_x_images = get_images(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03257ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_x_torch = torch.from_numpy(train_x_images).unsqueeze(dim=1)\n",
    "valid_x_torch = torch.from_numpy(valid_x_images).unsqueeze(dim=1)\n",
    "test_x_torch = torch.from_numpy(test_x_images).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "788aa0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2992, 1, 100, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f31717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2992])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_torch = torch.from_numpy(train_y)\n",
    "valid_y_torch = torch.from_numpy(valid_y)\n",
    "test_y_torch = torch.from_numpy(test_y)\n",
    "train_y_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bda2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if available\n",
    "if torch.cuda.is_available():\n",
    "    train_x_torch = train_x_torch.cuda()\n",
    "    train_y_torch = train_y_torch.cuda()\n",
    "    valid_x_torch = valid_x_torch.cuda()\n",
    "    valid_y_torch = valid_y_torch.cuda()\n",
    "    test_x_torch = test_x_torch.cuda()\n",
    "    test_y_torch = test_y_torch.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08cc17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(zip(train_x_torch, train_y_torch.to(dtype=torch.long)))\n",
    "test = list(zip(test_x_torch, test_y_torch.to(dtype=torch.long)))\n",
    "valid = list(zip(valid_x_torch, valid_y_torch.to(dtype=torch.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "636cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything into a data loader because too much data for gpu\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=16)\n",
    "testloader = DataLoader(test, batch_size=16)\n",
    "validloader = DataLoader(valid, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b1cb5",
   "metadata": {},
   "source": [
    "# Create CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cab59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# need to figure out what the numbers in Conv2d and other parts are / what to use for them\n",
    "\n",
    "class ConvNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        \n",
    "        # two layers for this cnn\n",
    "        self.cnn_layers = nn.Sequential (\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(1, 32, kernel_size=9, stride=1, padding=1),   # output = 94 x 94 x 32\n",
    "            nn.BatchNorm2d(32),                                     # same shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # output = 47 X 47 X 32\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(32, 32, kernel_size=9, stride=1, padding=1),  # output = 41 X 41 X 32\n",
    "            nn.BatchNorm2d(32),                                     # same shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # output = 20 X 20 X 32\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # output = 20 x 20 x 64\n",
    "            nn.BatchNorm2d(64),                                     # same shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # output = 10 X 10 X 64\n",
    "      \n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 10 * 10, 4)\n",
    "        )\n",
    "        \n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bfc6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNN(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "model = ConvNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00952669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0 loss = 0.689 train acc= 0.777 valid loss = 0.559 valid acc = 0.797\n",
      "At epoch 1 loss = 0.423 train acc= 0.857 valid loss = 0.466 valid acc = 0.837\n",
      "At epoch 2 loss = 0.309 train acc= 0.885 valid loss = 0.432 valid acc = 0.85\n",
      "At epoch 3 loss = 0.238 train acc= 0.906 valid loss = 0.403 valid acc = 0.857\n",
      "At epoch 4 loss = 0.184 train acc= 0.925 valid loss = 0.363 valid acc = 0.874\n",
      "At epoch 5 loss = 0.146 train acc= 0.939 valid loss = 0.34 valid acc = 0.876\n",
      "At epoch 6 loss = 0.115 train acc= 0.949 valid loss = 0.316 valid acc = 0.885\n",
      "At epoch 7 loss = 0.0919 train acc= 0.959 valid loss = 0.302 valid acc = 0.893\n",
      "At epoch 8 loss = 0.0736 train acc= 0.965 valid loss = 0.285 valid acc = 0.907\n",
      "At epoch 9 loss = 0.0587 train acc= 0.971 valid loss = 0.276 valid acc = 0.904\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        for i in range(len(labels)):\n",
    "            image = images[i].view(1, 1, 100, 100)\n",
    "            with torch.no_grad():\n",
    "                logps = model(image)\n",
    "            allprobs = torch.exp(logps)\n",
    "            prob = allprobs.tolist()[0]\n",
    "            hyp = prob.index(max(prob))\n",
    "            train_y = labels[i]\n",
    "            train_total += 1\n",
    "            if train_y.item() == hyp:\n",
    "                train_correct += 1\n",
    "                \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    \n",
    "    model.eval()\n",
    "    for images, labels in validloader:\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        valid_loss += loss.item()\n",
    "        for i in range(len(labels)):\n",
    "            image = images[i].view(1, 1, 100, 100)\n",
    "            with torch.no_grad():\n",
    "                logps = model(image)\n",
    "            allprobs = torch.exp(logps)\n",
    "            prob = allprobs.tolist()[0]\n",
    "            hyp = prob.index(max(prob))\n",
    "            valid_y = labels[i]\n",
    "            valid_total += 1\n",
    "            if valid_y.item() == hyp:\n",
    "                valid_correct += 1\n",
    "                \n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "    \n",
    "    print('At epoch', epoch, 'loss =', '%.3g'%(train_loss/len(trainloader)), 'train acc=', '%.3g'%(train_correct/train_total), 'valid loss =', '%.3g'%(valid_loss/len(validloader)), 'valid acc =', '%.3g'%(valid_correct/valid_total))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "conditional-gothic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16d809c70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a54bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9038461538461539\n"
     ]
    }
   ],
   "source": [
    "correct = 0.\n",
    "total = 0.\n",
    "\n",
    "hyps = []\n",
    "correct_labels = []\n",
    "\n",
    "model.eval()\n",
    "for images, labels in testloader:\n",
    "    for i in range(len(labels)):\n",
    "        image = images[i].view(1, 1, 100, 100)\n",
    "        with torch.no_grad():\n",
    "            logps = model(image)\n",
    "        allprobs = torch.exp(logps)\n",
    "        prob = allprobs.tolist()[0]\n",
    "        hyp = prob.index(max(prob))\n",
    "        hyps.append(hyp)\n",
    "        test_y = labels[i]\n",
    "        total += 1\n",
    "        correct_labels.append(test_y.item())\n",
    "        if test_y.item() == hyp:\n",
    "            correct += 1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9a00344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[207,   1,   3,  20],\n",
       "       [  3,  11,   2,  18],\n",
       "       [ 12,   2,  63,  10],\n",
       "       [ 16,   0,   3, 565]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(correct_labels, hyps)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "thorough-desktop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Bottoms       0.87      0.90      0.88       231\n",
      "        Hats       0.79      0.32      0.46        34\n",
      "       Shoes       0.89      0.72      0.80        87\n",
      "         Top       0.92      0.97      0.94       584\n",
      "\n",
      "    accuracy                           0.90       936\n",
      "   macro avg       0.87      0.73      0.77       936\n",
      "weighted avg       0.90      0.90      0.90       936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(correct_labels, hyps, target_names=['Bottoms', 'Hats', 'Shoes', 'Top']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-latitude",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
