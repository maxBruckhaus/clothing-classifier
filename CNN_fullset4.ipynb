{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ab76dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>T-Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>T-Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d3a1404-697f-479f-9090-c1ecd0413d27</td>\n",
       "      <td>Shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0c03127-9dfb-4573-8934-1958396937bf</td>\n",
       "      <td>Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>female-casual-peach-color-jeans-female-casual-...</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>lilac-jeans-wooden-background-lilac-jeans-wood...</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>jeans-image-table-48097904</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>jeans-white-background-classical-isolated-clos...</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>jeans-image-table-48100476</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5270 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image    label\n",
       "0                  ea7b6656-3f84-4eb3-9099-23e623fc1018  T-Shirt\n",
       "1                  ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa  T-Shirt\n",
       "2                  3b86d877-2b9e-4c8b-a6a2-1d87513309d0    Shoes\n",
       "3                  5d3a1404-697f-479f-9090-c1ecd0413d27   Shorts\n",
       "4                  b0c03127-9dfb-4573-8934-1958396937bf    Shirt\n",
       "...                                                 ...      ...\n",
       "5265  female-casual-peach-color-jeans-female-casual-...    Pants\n",
       "5266  lilac-jeans-wooden-background-lilac-jeans-wood...    Pants\n",
       "5267                         jeans-image-table-48097904    Pants\n",
       "5268  jeans-white-background-classical-isolated-clos...    Pants\n",
       "5269                         jeans-image-table-48100476    Pants\n",
       "\n",
       "[5270 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('images_4.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a415f90",
   "metadata": {},
   "source": [
    "# Encode labels, take sample of data into train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fa1093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 13, 10, ...,  7,  7,  7])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df.label)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a27a5846",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78eb944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, test_index in ss.split(images, labels):\n",
    "    train_x, test_x = images[train_index], images[test_index]\n",
    "    train_y, test_y = labels[train_index], labels[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "occupational-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62edb7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, valid_index in ss.split(train_x, train_y):\n",
    "    train_x, valid_x = train_x[train_index], train_x[valid_index]\n",
    "    train_y, valid_y = train_y[train_index], train_y[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f2438",
   "metadata": {},
   "source": [
    "# Get all images loaded in from sample and convert to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ddbd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def get_images(path_list):\n",
    "    train_img = []\n",
    "    for filename in path_list:\n",
    "        path = 'images_compressed/' + filename + '.jpg'\n",
    "        img = imread(path, as_gray=True)\n",
    "        img = resize(img, (100, 100))\n",
    "        img /= 255.0\n",
    "        img = img.astype('float32')\n",
    "        train_img.append(img)\n",
    "    return np.asarray(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f3c1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_images = get_images(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b3113b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3372, 100, 100)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7170de85",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_images = get_images(valid_x)\n",
    "test_x_images = get_images(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03257ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_x_torch = torch.from_numpy(train_x_images).unsqueeze(dim=1)\n",
    "valid_x_torch = torch.from_numpy(valid_x_images).unsqueeze(dim=1)\n",
    "test_x_torch = torch.from_numpy(test_x_images).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "788aa0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3372, 1, 100, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f31717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3372])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_torch = torch.from_numpy(train_y)\n",
    "valid_y_torch = torch.from_numpy(valid_y)\n",
    "test_y_torch = torch.from_numpy(test_y)\n",
    "train_y_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bda2b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gpu if available\n",
    "if torch.cuda.is_available():\n",
    "    train_x_torch = train_x_torch.cuda()\n",
    "    train_y_torch = train_y_torch.cuda()\n",
    "    valid_x_torch = valid_x_torch.cuda()\n",
    "    valid_y_torch = valid_y_torch.cuda()\n",
    "    test_x_torch = test_x_torch.cuda()\n",
    "    test_y_torch = test_y_torch.cuda()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08cc17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = list(zip(train_x_torch, train_y_torch.to(dtype=torch.long)))\n",
    "test = list(zip(test_x_torch, test_y_torch.to(dtype=torch.long)))\n",
    "valid = list(zip(valid_x_torch, valid_y_torch.to(dtype=torch.long)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "636cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything into a data loader because too much data for gpu\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainloader = DataLoader(train, batch_size=16)\n",
    "testloader = DataLoader(test, batch_size=16)\n",
    "validloader = DataLoader(valid, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b1cb5",
   "metadata": {},
   "source": [
    "# Create CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cab59c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# need to figure out what the numbers in Conv2d and other parts are / what to use for them\n",
    "\n",
    "class ConvNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        \n",
    "        # two layers for this cnn\n",
    "        self.cnn_layers = nn.Sequential (\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(1, 32, kernel_size=9, stride=1, padding=1),   # output = 94 x 94 x 32\n",
    "            nn.BatchNorm2d(32),                                     # same shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # output = 47 X 47 X 32\n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(32, 32, kernel_size=9, stride=1, padding=1),  # output = 41 X 41 X 32\n",
    "            nn.BatchNorm2d(32),                                     # same shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # output = 20 X 20 X 32\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),  # output = 20 x 20 x 64\n",
    "            nn.BatchNorm2d(64),                                     # same shape\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),                  # output = 10 X 10 X 64\n",
    "      \n",
    "        )\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 10 * 10, 15)\n",
    "        )\n",
    "        \n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "#         print(x.shape)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bfc6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNN(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 32, kernel_size=(9, 9), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace=True)\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "model = ConvNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00952669",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At epoch 0 loss = 2.02 train acc= 0.39 valid loss = 1.71 valid acc = 0.492\n",
      "At epoch 1 loss = 1.49 train acc= 0.527 valid loss = 1.45 valid acc = 0.565\n",
      "At epoch 2 loss = 1.22 train acc= 0.602 valid loss = 1.33 valid acc = 0.596\n",
      "At epoch 3 loss = 1.03 train acc= 0.656 valid loss = 1.28 valid acc = 0.62\n",
      "At epoch 4 loss = 0.877 train acc= 0.695 valid loss = 1.25 valid acc = 0.627\n",
      "At epoch 5 loss = 0.749 train acc= 0.726 valid loss = 1.22 valid acc = 0.645\n",
      "At epoch 6 loss = 0.64 train acc= 0.754 valid loss = 1.21 valid acc = 0.643\n",
      "At epoch 7 loss = 0.545 train acc= 0.785 valid loss = 1.21 valid acc = 0.647\n",
      "At epoch 8 loss = 0.462 train acc= 0.809 valid loss = 1.18 valid acc = 0.647\n",
      "At epoch 9 loss = 0.389 train acc= 0.835 valid loss = 1.18 valid acc = 0.646\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.\n",
    "    valid_loss = 0.\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        for i in range(len(labels)):\n",
    "            image = images[i].view(1, 1, 100, 100)\n",
    "            with torch.no_grad():\n",
    "                logps = model(image)\n",
    "            allprobs = torch.exp(logps)\n",
    "            prob = allprobs.tolist()[0]\n",
    "            hyp = prob.index(max(prob))\n",
    "            train_y = labels[i]\n",
    "            train_total += 1\n",
    "            if train_y.item() == hyp:\n",
    "                train_correct += 1\n",
    "                \n",
    "    train_losses.append(train_loss/len(trainloader))\n",
    "    \n",
    "    model.eval()\n",
    "    for images, labels in validloader:\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        valid_loss += loss.item()\n",
    "        for i in range(len(labels)):\n",
    "            image = images[i].view(1, 1, 100, 100)\n",
    "            with torch.no_grad():\n",
    "                logps = model(image)\n",
    "            allprobs = torch.exp(logps)\n",
    "            prob = allprobs.tolist()[0]\n",
    "            hyp = prob.index(max(prob))\n",
    "            valid_y = labels[i]\n",
    "            valid_total += 1\n",
    "            if valid_y.item() == hyp:\n",
    "                valid_correct += 1\n",
    "                \n",
    "    valid_losses.append(valid_loss/len(validloader))\n",
    "    \n",
    "    print('At epoch', epoch, 'loss =', '%.3g'%(train_loss/len(trainloader)), 'train acc=', '%.3g'%(train_correct/train_total), 'valid loss =', '%.3g'%(valid_loss/len(validloader)), 'valid acc =', '%.3g'%(valid_correct/valid_total))\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "powerful-kingdom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x16a6bcd60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92a54bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6110056925996205\n"
     ]
    }
   ],
   "source": [
    "correct = 0.\n",
    "total = 0.\n",
    "\n",
    "hyps = []\n",
    "correct_labels = []\n",
    "\n",
    "model.eval()\n",
    "for images, labels in testloader:\n",
    "    for i in range(len(labels)):\n",
    "        image = images[i].view(1, 1, 100, 100)\n",
    "        with torch.no_grad():\n",
    "            logps = model(image)\n",
    "        allprobs = torch.exp(logps)\n",
    "        prob = allprobs.tolist()[0]\n",
    "        hyp = prob.index(max(prob))\n",
    "        hyps.append(hyp)\n",
    "        test_y = labels[i]\n",
    "        total += 1\n",
    "        correct_labels.append(test_y.item())\n",
    "        if test_y.item() == hyp:\n",
    "            correct += 1\n",
    "\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9a00344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8,   0,   0,   0,   1,   5,   3,   1,   0,   3,   0,   0,   1,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
       "          3,   1],\n",
       "       [  2,   0,  31,   0,   0,   6,   1,   4,   1,   6,   0,   3,   2,\n",
       "         14,   1],\n",
       "       [  1,   0,   0,   9,   0,   7,   0,   3,   0,   4,   3,   1,   3,\n",
       "          3,   0],\n",
       "       [  0,   0,   1,   0,   3,  10,   3,   0,   0,   1,   1,   0,   0,\n",
       "          1,   0],\n",
       "       [  1,   0,   0,   2,   3,  94,   4,   3,   0,  14,   2,   1,   1,\n",
       "         13,   2],\n",
       "       [  0,   0,   4,   0,   3,  21,  16,   3,   2,   9,   0,   1,   2,\n",
       "          1,   0],\n",
       "       [  1,   0,   1,   0,   2,   2,   1, 130,   1,   9,   2,   7,   0,\n",
       "          3,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   1,   0,   8,   3,   0,   0,   0,\n",
       "         11,   0],\n",
       "       [  3,   0,   2,   0,   0,  21,   3,   5,   0,  64,   4,   2,   0,\n",
       "          9,   0],\n",
       "       [  0,   0,   2,   1,   0,   2,   1,   9,   0,   1,  62,   8,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   1,   0,   0,   0,   0,  12,   0,   1,   2,  44,   2,\n",
       "          0,   0],\n",
       "       [  0,   0,   3,   0,   0,   3,   0,   3,   0,   5,   1,   6,   7,\n",
       "          2,   1],\n",
       "       [  0,   0,   4,   1,   1,  11,   2,   2,   5,   9,   1,   3,   0,\n",
       "        162,   1],\n",
       "       [  0,   0,   3,   0,   0,   2,   0,   0,   0,   0,   1,   0,   1,\n",
       "         10,   6]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(correct_labels, hyps)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "thorough-desktop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Blazer       0.50      0.36      0.42        22\n",
      "      Blouse       0.00      0.00      0.00         5\n",
      "       Dress       0.60      0.44      0.50        71\n",
      "         Hat       0.69      0.26      0.38        34\n",
      "      Hoodie       0.23      0.15      0.18        20\n",
      "  Longsleeve       0.51      0.67      0.58       140\n",
      "     Outwear       0.46      0.26      0.33        62\n",
      "       Pants       0.74      0.82      0.78       159\n",
      "        Polo       0.47      0.33      0.39        24\n",
      "       Shirt       0.50      0.57      0.53       113\n",
      "       Shoes       0.78      0.72      0.75        86\n",
      "      Shorts       0.58      0.71      0.64        62\n",
      "       Skirt       0.37      0.23      0.28        31\n",
      "     T-Shirt       0.70      0.80      0.75       202\n",
      "  Undershirt       0.50      0.26      0.34        23\n",
      "\n",
      "    accuracy                           0.61      1054\n",
      "   macro avg       0.51      0.44      0.46      1054\n",
      "weighted avg       0.60      0.61      0.60      1054\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(correct_labels, hyps, target_names=['Blazer', 'Blouse', 'Dress', 'Hat', 'Hoodie', 'Longsleeve',\n",
    "       'Outwear', 'Pants', 'Polo', 'Shirt', 'Shoes', 'Shorts', 'Skirt',\n",
    "       'T-Shirt', 'Undershirt']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
