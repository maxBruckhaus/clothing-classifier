{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sudden-titanium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d3a1404-697f-479f-9090-c1ecd0413d27</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0c03127-9dfb-4573-8934-1958396937bf</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>3855ea22-5e7f-411f-b1fa-6db27a676c06</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>dfd4079d-967b-4b3e-8574-fbac11b58103</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>5379356a-40ee-4890-b416-2336a7d84061</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>65507fb8-3456-4c15-b53e-d1b03bf71a59</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>32b99302-cec7-4dec-adfa-3d4029674209</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4677 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image    label\n",
       "0     ea7b6656-3f84-4eb3-9099-23e623fc1018      Top\n",
       "1     ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa      Top\n",
       "2     3b86d877-2b9e-4c8b-a6a2-1d87513309d0    Shoes\n",
       "3     5d3a1404-697f-479f-9090-c1ecd0413d27  Bottoms\n",
       "4     b0c03127-9dfb-4573-8934-1958396937bf      Top\n",
       "...                                    ...      ...\n",
       "4672  3855ea22-5e7f-411f-b1fa-6db27a676c06    Shoes\n",
       "4673  dfd4079d-967b-4b3e-8574-fbac11b58103  Bottoms\n",
       "4674  5379356a-40ee-4890-b416-2336a7d84061  Bottoms\n",
       "4675  65507fb8-3456-4c15-b53e-d1b03bf71a59    Shoes\n",
       "4676  32b99302-cec7-4dec-adfa-3d4029674209  Bottoms\n",
       "\n",
       "[4677 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "df = pd.read_csv('images_2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "varied-involvement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Top        2916\n",
       "Bottoms    1156\n",
       "Shoes       433\n",
       "Hat         172\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stopped-watts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 2, ..., 0, 2, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(df.label)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "crazy-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "through-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.1)\n",
    "for _, group_index in ss.split(images, labels):\n",
    "    group_x = images[group_index].to_numpy()\n",
    "    group_y = labels[group_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "lucky-advance",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, test_index in ss.split(group_x, group_y):\n",
    "    train_x, test_x = group_x[train_index], group_x[test_index]\n",
    "    train_y, test_y = group_y[train_index], group_y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "impaired-patrick",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, valid_index in ss.split(train_x, train_y):\n",
    "    train_x, valid_x = train_x[train_index], train_x[valid_index]\n",
    "    train_y, valid_y = train_y[train_index], train_y[valid_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "empty-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images and convert to tensor\n",
    "\n",
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "def get_images(path_list):\n",
    "    train_img = []\n",
    "    for filename in path_list:\n",
    "        path = 'images_compressed/' + filename + '.jpg'\n",
    "        img = imread(path, as_gray=True)\n",
    "        img = resize(img, (100, 100))\n",
    "        img /= 255.0\n",
    "        img = img.astype('float32')\n",
    "        train_img.append(img)\n",
    "    return np.asarray(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "enormous-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_images = get_images(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "third-wisconsin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299,)\n",
      "(299, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(train_x_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "subjective-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x_images = get_images(valid_x)\n",
    "test_x_images = get_images(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bearing-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_x_torch = torch.from_numpy(train_x_images).unsqueeze(dim=1)\n",
    "valid_x_torch = torch.from_numpy(valid_x_images).unsqueeze(dim=1)\n",
    "test_x_torch = torch.from_numpy(test_x_images).unsqueeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "amino-hardwood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([299, 1, 100, 100])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "brazilian-sweet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([299])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_torch = torch.from_numpy(train_y)\n",
    "valid_y_torch = torch.from_numpy(valid_y)\n",
    "test_y_torch = torch.from_numpy(test_y)\n",
    "train_y_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sharing-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# need to figure out what the numbers in Conv2d and other parts are / what to use for them\n",
    "\n",
    "class ConvNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        \n",
    "        # two layers for this cnn\n",
    "        self.cnn_layers = nn.Sequential (\n",
    "            # Defining a 2D convolution layer\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Defining another 2D convolution layer\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "    \n",
    "        self.linear_layers = nn.Sequential(\n",
    "            Linear(32 * 5 * 5, 4)\n",
    "        )\n",
    "\n",
    "    \n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        output = self.cnn_layers(x)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        output = self.linear_layers(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "coordinate-vinyl",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNN(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=800, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "\n",
    "model = ConvNN()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "pediatric-context",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-86bad5c6409d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print('At epoch', epoch, 'loss=', running_loss/len(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "intended-convergence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ni = 0\\nplt.figure(figsize=(10,10))\\nplt.subplot(221), plt.imshow(train_x[i], cmap='gray')\\nplt.subplot(222), plt.imshow(train_x[i+25], cmap='gray')\\nplt.subplot(223), plt.imshow(train_x[i+50], cmap='gray')\\nplt.subplot(224), plt.imshow(train_x[i+75], cmap='gray')\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualizing images\n",
    "'''\n",
    "i = 0\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221), plt.imshow(train_x[i], cmap='gray')\n",
    "plt.subplot(222), plt.imshow(train_x[i+25], cmap='gray')\n",
    "plt.subplot(223), plt.imshow(train_x[i+50], cmap='gray')\n",
    "plt.subplot(224), plt.imshow(train_x[i+75], cmap='gray')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
