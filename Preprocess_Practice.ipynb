{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "sudden-titanium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d3a1404-697f-479f-9090-c1ecd0413d27</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0c03127-9dfb-4573-8934-1958396937bf</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4672</th>\n",
       "      <td>3855ea22-5e7f-411f-b1fa-6db27a676c06</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>dfd4079d-967b-4b3e-8574-fbac11b58103</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>5379356a-40ee-4890-b416-2336a7d84061</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>65507fb8-3456-4c15-b53e-d1b03bf71a59</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>32b99302-cec7-4dec-adfa-3d4029674209</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4677 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     image    label\n",
       "0     ea7b6656-3f84-4eb3-9099-23e623fc1018      Top\n",
       "1     ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa      Top\n",
       "2     3b86d877-2b9e-4c8b-a6a2-1d87513309d0    Shoes\n",
       "3     5d3a1404-697f-479f-9090-c1ecd0413d27  Bottoms\n",
       "4     b0c03127-9dfb-4573-8934-1958396937bf      Top\n",
       "...                                    ...      ...\n",
       "4672  3855ea22-5e7f-411f-b1fa-6db27a676c06    Shoes\n",
       "4673  dfd4079d-967b-4b3e-8574-fbac11b58103  Bottoms\n",
       "4674  5379356a-40ee-4890-b416-2336a7d84061  Bottoms\n",
       "4675  65507fb8-3456-4c15-b53e-d1b03bf71a59    Shoes\n",
       "4676  32b99302-cec7-4dec-adfa-3d4029674209  Bottoms\n",
       "\n",
       "[4677 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('images_2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "varied-involvement",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Top        2916\n",
       "Bottoms    1156\n",
       "Shoes       433\n",
       "Hat         172\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "sweet-monday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ea7b6656-3f84-4eb3-9099-23e623fc1018</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3b86d877-2b9e-4c8b-a6a2-1d87513309d0</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5d3a1404-697f-479f-9090-c1ecd0413d27</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b0c03127-9dfb-4573-8934-1958396937bf</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>6d08108f-89b2-4b59-afba-8f85892bffa7</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>e83aabcc-a45c-4da6-87ec-cb41580b3bd4</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>a28a7997-95cb-4e05-907d-bb7a5c35c7f9</td>\n",
       "      <td>Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>097b9af0-483a-4b41-991c-3468877db077</td>\n",
       "      <td>Top</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>36e2b110-6be7-4c46-a865-34ca99808c11</td>\n",
       "      <td>Bottoms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    image    label\n",
       "0    ea7b6656-3f84-4eb3-9099-23e623fc1018      Top\n",
       "1    ea2ffd4d-9b25-4ca8-9dc2-bd27f1cc59fa      Top\n",
       "2    3b86d877-2b9e-4c8b-a6a2-1d87513309d0    Shoes\n",
       "3    5d3a1404-697f-479f-9090-c1ecd0413d27  Bottoms\n",
       "4    b0c03127-9dfb-4573-8934-1958396937bf      Top\n",
       "..                                    ...      ...\n",
       "995  6d08108f-89b2-4b59-afba-8f85892bffa7      Top\n",
       "996  e83aabcc-a45c-4da6-87ec-cb41580b3bd4      Top\n",
       "997  a28a7997-95cb-4e05-907d-bb7a5c35c7f9    Shoes\n",
       "998  097b9af0-483a-4b41-991c-3468877db077      Top\n",
       "999  36e2b110-6be7-4c46-a865-34ca99808c11  Bottoms\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df.iloc[0:1000, :]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "weekly-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['image']\n",
    "Y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "third-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "empty-bradford",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-1d13817b83c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'images_original/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimg_code\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mresized_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# normalize pixel values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    145\u001b[0m                              \"documentation of numpy.pad for more info.\")\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[0m\u001b[1;32m    148\u001b[0m                                     cval=cval, mode=ndi_mode)\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[0;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[0m\u001b[1;32m    342\u001b[0m                               mode, cval, truncate)\n\u001b[1;32m    343\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[0;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/scipy/ndimage/filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[0;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    131\u001b[0m                          '(len(weights)-1) // 2')\n\u001b[1;32m    132\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[0m\u001b[1;32m    134\u001b[0m                           origin)\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# prepare training images\n",
    "\n",
    "train_img = []\n",
    "test_img = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "for img_code in new_df['image']:\n",
    "    img_path = 'images_original/' + img_code + '.jpg'\n",
    "    img = imread(img_path, as_gray=True)\n",
    "    resized_img = resize(img, (100, 100))\n",
    "    \n",
    "    # normalize pixel values\n",
    "    resized_img /= 255\n",
    "    # converty pixel type to float 32\n",
    "    resized_img = resized_img.astype('float32')\n",
    "    \n",
    "    # split images into train (80%) and test (20%)\n",
    "    if (i < 800):\n",
    "        train_img.append(resized_img)\n",
    "    else:\n",
    "        test_img.append(resized_img)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert list to numpy array\n",
    "\n",
    "train_x = np.array(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target\n",
    "\n",
    "train_y = new_df['label'].values\n",
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing images\n",
    "i = 0\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(221), plt.imshow(train_x[i], cmap='gray')\n",
    "plt.subplot(222), plt.imshow(train_x[i+25], cmap='gray')\n",
    "plt.subplot(223), plt.imshow(train_x[i+50], cmap='gray')\n",
    "plt.subplot(224), plt.imshow(train_x[i+75], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
